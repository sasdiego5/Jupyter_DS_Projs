{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diego Orejuela\n",
    "## Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement regression on the dataset provided.\n",
    "Dataset: The Housing dataset contains information about houses in the suburbs of a US city in 1970s. The features\n",
    "of the 506 samples in the dataset are summarized here:\n",
    "* CRIM: Per capita crime rate by town\n",
    "* ZN: Proportion of residential land zoned for lots over 25,000 sq. ft.\n",
    "* INDUS: Proportion of non-retail business acres per town\n",
    "* CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "* NOX: Nitric oxide concentration (parts per 10 million)\n",
    "* RM: Average number of rooms per dwelling\n",
    "* AGE: Proportion of owner-occupied units built prior to 1940\n",
    "* DIS: Weighted distances to five Boston employment centers\n",
    "* RAD: Index of accessibility to radial highways\n",
    "* TAX: Full-value property tax rate per 10,000 usd\n",
    "* PTRATIO: Pupil-teacher ratio by town\n",
    "* B: 1000(Bk - 0.63)^2, where Bk is the proportion of [people of African American descent] by town \n",
    "* LSTAT: Percentage of lower status of the population\n",
    "* MEDV: Median value of owner-occupied homes in 1000s usd\n",
    "\n",
    "The house prices (MEDV) will be regarder as the target variable (the variable that we want to predict using one or more of the 13 explanatory variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset into a pandas dataframe and display the first 5 lines of the dataset along with the column headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>6.5750</td>\n",
       "      <td>65.20</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.30</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>6.4210</td>\n",
       "      <td>78.90</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.80</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>7.1850</td>\n",
       "      <td>61.10</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.80</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>6.9980</td>\n",
       "      <td>45.80</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.70</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>7.1470</td>\n",
       "      <td>54.20</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.70</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM     ZN  INDUS CHAS     NOX      RM    AGE     DIS RAD    TAX  \\\n",
       "0  0.00632  18.00  2.310    0  0.5380  6.5750  65.20  4.0900   1  296.0   \n",
       "1  0.02731   0.00  7.070    0  0.4690  6.4210  78.90  4.9671   2  242.0   \n",
       "2  0.02729   0.00  7.070    0  0.4690  7.1850  61.10  4.9671   2  242.0   \n",
       "3  0.03237   0.00  2.180    0  0.4580  6.9980  45.80  6.0622   3  222.0   \n",
       "4  0.06905   0.00  2.180    0  0.4580  7.1470  54.20  6.0622   3  222.0   \n",
       "\n",
       "  PTRATIO       B LSTAT   MEDV  \n",
       "0   15.30  396.90  4.98  24.00  \n",
       "1   17.80  396.90  9.14  21.60  \n",
       "2   17.80  392.83  4.03  34.70  \n",
       "3   18.70  394.63  2.94  33.40  \n",
       "4   18.70  396.90  5.33  36.20  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "dataset = pd.read_csv('data.txt',header=None)\n",
    "\n",
    "#split dataset by whitespace into columns\n",
    "dataset = pd.DataFrame(dataset[0].str.split(expand=True))\n",
    "\n",
    "#look for missing values\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "col_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO','B', 'LSTAT', 'MEDV']\n",
    "\n",
    "dataset.columns = col_names\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training (70%) and testing set (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[: , 0:13].values\n",
    "y = dataset.iloc[ : ,13].values\n",
    "\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# add a column of ones to X (corresponding to intercept term)\n",
    "X = np.append(arr = np.ones((506,1)).astype(int), values = X, axis = 1)\n",
    "\n",
    "#split data into Training and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Build a linear regression model with all the variables using Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Equation: (XTX)^-1 XTy\n",
    "xTx = X_train.T.dot(X_train)\n",
    "xTx = np.linalg.inv(xTx)\n",
    "xTx_xT = xTx.dot(X_train.T)\n",
    "w = xTx_xT.dot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the weight parameters for model 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.79371077e+01, -1.21310401e-01,  4.44664254e-02,  1.13416945e-02,\n",
       "        2.51124642e+00, -1.62312529e+01,  3.85906801e+00, -9.98516565e-03,\n",
       "       -1.50026956e+00,  2.42143466e-01, -1.10716124e-02, -1.01775264e+00,\n",
       "        6.81446545e-03, -4.86738066e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model 1 make a prediction on the test set and Calculate Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: \n",
      " [22.6 50.  23.   8.3 21.2 19.9 20.6 18.7 16.1 18.6  8.8 17.2 14.9 10.5\n",
      " 50.  29.  23.  33.3 29.4 21.  23.8 19.1 20.4 29.1 19.3 23.1 19.6 19.4\n",
      " 38.7 18.7 14.6 20.  20.5 20.1 23.6 16.8  5.6 50.  14.5 13.3 23.9 20.\n",
      " 19.8 13.8 16.5 21.6 20.3 17.  11.8 27.5 15.6 23.1 24.3 42.8 15.6 21.7\n",
      " 17.1 17.2 15.  21.7 18.6 21.  33.1 31.5 20.1 29.8 15.2 15.  27.5 22.6\n",
      " 20.  21.4 23.5 31.2 23.7  7.4 48.3 24.4 22.6 18.3 23.3 17.1 27.9 44.8\n",
      " 50.  23.  21.4 10.2 23.3 23.2 18.9 13.4 21.9 24.8 11.9 24.3 13.8 24.7\n",
      " 14.1 18.7 28.1 19.8 26.7 21.7 22.  22.9 10.4 21.9 20.6 26.4 41.3 17.2\n",
      " 27.1 20.4 16.5 24.4  8.4 23.   9.7 50.  30.5 12.3 19.4 21.2 20.3 18.8\n",
      " 33.4 18.5 19.6 33.2 13.1  7.5 13.6 17.4  8.4 35.4 24.  13.4 26.2  7.2\n",
      " 13.1 24.5 37.2 25.  24.1 16.6 32.9 36.2 11.   7.2 22.8 28.7] \n",
      "\n",
      "Predict Set: \n",
      " [24.9357079  23.75163164 29.32638296 11.97534566 21.37272478 19.19148525\n",
      " 20.5717479  21.21154015 19.04572003 20.35463238  5.44119126 16.93688709\n",
      " 17.15482272  5.3928209  40.20270696 32.31327348 22.46213268 36.50124666\n",
      " 31.03737014 23.17124551 24.74815321 24.49939403 20.6595791  30.4547583\n",
      " 22.32487164 10.18932894 17.44286422 18.26103077 35.63299326 20.81960303\n",
      " 18.27218007 17.72047628 19.33772473 23.62254823 28.97766856 19.45036239\n",
      " 11.13170639 24.81843595 18.05294835 15.59712226 26.21043403 20.81140432\n",
      " 22.17349382 15.48367365 22.62261604 24.88561528 19.74754478 23.0465628\n",
      "  9.84579105 24.36378793 21.47849008 17.62118176 24.39160873 29.95102691\n",
      " 13.57219422 21.53645439 20.53306273 15.03433182 14.3232289  22.11929299\n",
      " 17.07321915 21.54141094 32.96766968 31.371599   17.7860591  32.75069556\n",
      " 18.74795323 19.21428022 19.41970047 23.08087809 22.87732816 24.06399098\n",
      " 30.52824406 28.71453508 25.90763165  5.17596718 36.8709072  23.76983849\n",
      " 27.26064379 19.25849042 28.41860517 19.3008798  18.94922353 38.00154059\n",
      " 39.44096748 23.72297885 24.83722534 16.52015743 25.9970546  16.73997072\n",
      " 15.48656983 13.52825536 24.12884363 30.76919578 22.18731163 19.8848644\n",
      "  0.42275479 24.86785849 16.05692    17.42486412 25.49798527 22.35171315\n",
      " 32.66562689 22.04428746 27.29799885 23.20302026  6.86196574 14.869251\n",
      " 22.31804948 29.18125768 33.22568234 13.24392523 19.67195771 20.7502616\n",
      " 12.02271319 23.50067006  5.55662571 19.87634689  9.27059783 44.81787339\n",
      " 30.56017983 12.44394048 17.33192202 21.48313292 23.52664913 20.49877266\n",
      " 35.09161099 13.22639935 20.70321163 35.35582833 19.45050576 13.81603561\n",
      " 14.15654562 23.03678503 15.07521258 30.9662041  25.23236632 15.43763716\n",
      " 24.06406534  9.93080346 15.01618901 21.06098873 32.87115732 27.80927747\n",
      " 25.91293794 15.27877362 30.97489404 27.81107682 14.5068157   7.57369946\n",
      " 28.3348068  25.04341153]\n",
      "\n",
      " Mean Squared Error:  27.19596576688312\n"
     ]
    }
   ],
   "source": [
    "y_pred_m1 = X_test.dot(w)\n",
    "print( \"Test Set: \\n\", y_test,\"\\n\")\n",
    "print( \"Predict Set: \\n\", y_pred_m1)\n",
    "\n",
    "#Mean Squared Error\n",
    "mse_m1 = np.square(np.subtract(y_pred_m1, y_test)).mean()\n",
    "print(\"\\n Mean Squared Error: \",mse_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Using scikit-learn  build a Linear Regression model with all the variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Multiple Linear Regression to Training Set\n",
    "# import LinearRegression class from scikit-learn\n",
    "# initialize a LinearRegression object and fit X and y train sets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "mlrObj_m2 = LinearRegression()\n",
    "mlrObj_m2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the weight parameters for model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.21310401e-01,  4.44664254e-02,  1.13416945e-02,\n",
       "        2.51124642e+00, -1.62312529e+01,  3.85906801e+00, -9.98516565e-03,\n",
       "       -1.50026956e+00,  2.42143466e-01, -1.10716124e-02, -1.01775264e+00,\n",
       "        6.81446545e-03, -4.86738066e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight parameters\n",
    "mlrObj_m2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model 2 make a prediction on the test set and Calculate Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: \n",
      " [22.6 50.  23.   8.3 21.2 19.9 20.6 18.7 16.1 18.6  8.8 17.2 14.9 10.5\n",
      " 50.  29.  23.  33.3 29.4 21.  23.8 19.1 20.4 29.1 19.3 23.1 19.6 19.4\n",
      " 38.7 18.7 14.6 20.  20.5 20.1 23.6 16.8  5.6 50.  14.5 13.3 23.9 20.\n",
      " 19.8 13.8 16.5 21.6 20.3 17.  11.8 27.5 15.6 23.1 24.3 42.8 15.6 21.7\n",
      " 17.1 17.2 15.  21.7 18.6 21.  33.1 31.5 20.1 29.8 15.2 15.  27.5 22.6\n",
      " 20.  21.4 23.5 31.2 23.7  7.4 48.3 24.4 22.6 18.3 23.3 17.1 27.9 44.8\n",
      " 50.  23.  21.4 10.2 23.3 23.2 18.9 13.4 21.9 24.8 11.9 24.3 13.8 24.7\n",
      " 14.1 18.7 28.1 19.8 26.7 21.7 22.  22.9 10.4 21.9 20.6 26.4 41.3 17.2\n",
      " 27.1 20.4 16.5 24.4  8.4 23.   9.7 50.  30.5 12.3 19.4 21.2 20.3 18.8\n",
      " 33.4 18.5 19.6 33.2 13.1  7.5 13.6 17.4  8.4 35.4 24.  13.4 26.2  7.2\n",
      " 13.1 24.5 37.2 25.  24.1 16.6 32.9 36.2 11.   7.2 22.8 28.7] \n",
      "\n",
      "Predict Set: \n",
      " [24.9357079  23.75163164 29.32638296 11.97534566 21.37272478 19.19148525\n",
      " 20.5717479  21.21154015 19.04572003 20.35463238  5.44119126 16.93688709\n",
      " 17.15482272  5.3928209  40.20270696 32.31327348 22.46213268 36.50124666\n",
      " 31.03737014 23.17124551 24.74815321 24.49939403 20.6595791  30.4547583\n",
      " 22.32487164 10.18932894 17.44286422 18.26103077 35.63299326 20.81960303\n",
      " 18.27218007 17.72047628 19.33772473 23.62254823 28.97766856 19.45036239\n",
      " 11.13170639 24.81843595 18.05294835 15.59712226 26.21043403 20.81140432\n",
      " 22.17349382 15.48367365 22.62261604 24.88561528 19.74754478 23.0465628\n",
      "  9.84579105 24.36378793 21.47849008 17.62118176 24.39160873 29.95102691\n",
      " 13.57219422 21.53645439 20.53306273 15.03433182 14.3232289  22.11929299\n",
      " 17.07321915 21.54141094 32.96766968 31.371599   17.7860591  32.75069556\n",
      " 18.74795323 19.21428022 19.41970047 23.08087809 22.87732816 24.06399098\n",
      " 30.52824406 28.71453508 25.90763165  5.17596718 36.8709072  23.76983849\n",
      " 27.26064379 19.25849042 28.41860517 19.3008798  18.94922353 38.00154059\n",
      " 39.44096748 23.72297885 24.83722534 16.52015743 25.9970546  16.73997072\n",
      " 15.48656983 13.52825536 24.12884363 30.76919578 22.18731163 19.8848644\n",
      "  0.42275479 24.86785849 16.05692    17.42486412 25.49798527 22.35171315\n",
      " 32.66562689 22.04428746 27.29799885 23.20302026  6.86196574 14.869251\n",
      " 22.31804948 29.18125768 33.22568234 13.24392523 19.67195771 20.7502616\n",
      " 12.02271319 23.50067006  5.55662571 19.87634689  9.27059783 44.81787339\n",
      " 30.56017983 12.44394048 17.33192202 21.48313292 23.52664913 20.49877266\n",
      " 35.09161099 13.22639935 20.70321163 35.35582833 19.45050576 13.81603561\n",
      " 14.15654562 23.03678503 15.07521258 30.9662041  25.23236632 15.43763716\n",
      " 24.06406534  9.93080346 15.01618901 21.06098873 32.87115732 27.80927747\n",
      " 25.91293794 15.27877362 30.97489404 27.81107682 14.5068157   7.57369946\n",
      " 28.3348068  25.04341153]\n",
      "\n",
      " Mean Squared Error:  27.195965766883194\n"
     ]
    }
   ],
   "source": [
    "# Predicting on Test Set\n",
    "y_pred_m2 = mlrObj_m2.predict(X_test)\n",
    "print( \"Test Set: \\n\", y_test,\"\\n\")\n",
    "print( \"Predict Set: \\n\", y_pred_m2)\n",
    "\n",
    "#Mean Squared Error\n",
    "mse_m2 = np.square(np.subtract(y_pred_m2, y_test)).mean()\n",
    "print(\"\\n Mean Squared Error: \",mse_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function forwardSelection(x, sl) to implement the forward feature selection technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.37062373e-216]\n",
      "[3.55554392e-07]\n",
      "[8.87823995e-38]\n",
      "[9.55082965e-74]\n",
      "[1.48290625e-12]\n",
      "[5.53284345e-160]\n",
      "[3.74375819e-256]\n",
      "[1.8485505e-115]\n",
      "[1.51525782e-146]\n",
      "[2.24637612e-48]\n",
      "[1.02622585e-108]\n",
      "[1.51036031e-181]\n",
      "[3.98926958e-219]\n",
      "[2.71419481e-67]\n",
      "[2.48722887e-74 6.95022903e-34]\n",
      "[2.04117444e-270 3.50077821e-022]\n",
      "[1.27852731e-230 1.88182618e-012]\n",
      "[1.61635352e-215 2.41985348e-033]\n",
      "[8.14575415e-248 1.89019593e-004]\n",
      "[2.33956493e-135 3.19222070e-039]\n",
      "[5.07510979e-169 2.11454128e-028]\n",
      "[2.14231854e-113 2.59936465e-003]\n",
      "[2.34800721e-232 7.24337088e-025]\n",
      "[2.64223375e-187 5.10142300e-040]\n",
      "[2.67570806e-126 9.87378369e-052]\n",
      "[7.52189309e-41 2.48299534e-03]\n",
      "[1.61368901e-261 4.81185167e-073]\n",
      "[3.47225760e-27 6.66936548e-41 6.68764941e-01]\n",
      "[2.01550663e-257 1.24430924e-054 1.77647804e-003]\n",
      "[2.38938025e-223 1.63865679e-062 1.77928703e-001]\n",
      "[1.61536326e-252 7.40186618e-042 1.48998799e-001]\n",
      "[9.23297771e-259 7.36380657e-074 1.88614494e-005]\n",
      "[1.79592847e-112 1.13706862e-035 4.33402411e-001]\n",
      "[5.20920834e-204 1.77748473e-046 4.01490878e-001]\n",
      "[3.52271203e-174 2.44700080e-073 8.87626375e-004]\n",
      "[6.41377786e-261 4.63085790e-051 1.78549115e-002]\n",
      "[1.88276399e-219 7.66796032e-038 1.65280209e-004]\n",
      "[3.23805642e-103 3.71523199e-031 1.08106073e-009]\n",
      "[2.41959619e-100 1.63653523e-073 5.51159907e-004]\n",
      "[7.73479341e-24 7.94420821e-36 1.64465986e-14 2.72580826e-06]\n",
      "[5.65690228e-102 1.85038830e-024 1.94337259e-009 3.21975116e-003]\n",
      "[1.45494317e-93 4.46050617e-30 2.78435645e-09 8.38643384e-01]\n",
      "[3.74905650e-102 1.14030605e-024 3.22173257e-009 8.75791684e-001]\n",
      "[1.82357744e-100 1.99448399e-032 8.06356240e-009 1.45826560e-004]\n",
      "[1.80597319e-87 2.57559545e-21 1.52981774e-09 9.22225915e-01]\n",
      "[3.27538744e-98 3.42413891e-24 9.63227494e-10 3.16948970e-01]\n",
      "[1.92337104e-102 1.71140230e-031 1.67800427e-008 1.63668085e-002]\n",
      "[1.81313339e-100 4.76472819e-027 1.04793775e-008 2.63452546e-001]\n",
      "[5.12335043e-103 1.92841116e-023 1.90020060e-007 4.05529824e-002]\n",
      "[1.48048433e-86 2.32065852e-27 2.55036297e-13 1.01850395e-07]\n",
      "[4.64966797e-26 1.92811270e-27 6.14955853e-14 1.46799719e-04\n",
      " 4.45720628e-03]\n",
      "[9.43506068e-87 1.20023016e-23 1.24552770e-12 3.09859601e-06\n",
      " 1.44080537e-01]\n",
      "[4.09013319e-81 6.45666251e-27 5.31899399e-13 1.01477278e-07\n",
      " 7.45917713e-01]\n",
      "[1.48116513e-86 5.11632476e-24 3.05837881e-13 7.05641710e-08\n",
      " 3.73627768e-01]\n",
      "[1.03642151e-84 1.44321329e-28 2.98541098e-12 1.70938648e-07\n",
      " 2.44840624e-04]\n",
      "[2.44305849e-71 2.60084328e-20 2.58417578e-13 8.48601818e-08\n",
      " 5.17251162e-01]\n",
      "[4.06505853e-81 9.02943165e-23 1.66791549e-13 5.76128775e-08\n",
      " 1.41682914e-01]\n",
      "[1.32125362e-89 1.53128351e-30 3.55105982e-12 1.00488600e-09\n",
      " 1.20498215e-04]\n",
      "[1.52332920e-86 6.64800867e-27 3.41813761e-13 1.03390802e-07\n",
      " 2.58741439e-01]\n",
      "[5.49625497e-86 1.28412439e-23 3.01363832e-11 8.81702875e-07\n",
      " 7.84430232e-01]\n",
      "[6.68887958e-24 1.67777955e-32 1.34976303e-15 1.08882796e-05\n",
      " 1.27375622e-06 4.20082933e-05]\n",
      "[2.32180432e-90 3.40849042e-27 3.81569305e-11 7.46779575e-08\n",
      " 3.05159516e-05 2.91348109e-02]\n",
      "[6.54718145e-82 2.06285852e-31 9.84298961e-09 3.27954830e-10\n",
      " 3.25345879e-06 8.10386714e-03]\n",
      "[5.72017186e-90 1.56705168e-25 3.04993522e-09 2.00261272e-09\n",
      " 4.98434496e-05 1.14666699e-01]\n",
      "[5.32173861e-87 5.75910486e-31 2.10422725e-11 3.32705892e-09\n",
      " 6.87258328e-04 1.41016536e-03]\n",
      "[8.09992448e-72 5.35596012e-20 3.22352717e-10 6.63628468e-10\n",
      " 2.99164327e-05 7.89536414e-02]\n",
      "[2.51258527e-81 9.10293740e-22 1.80022177e-11 5.95206181e-10\n",
      " 1.69941925e-04 2.15031538e-01]\n",
      "[2.63148234e-89 9.88510323e-30 1.45998817e-10 1.34514128e-08\n",
      " 2.38144684e-04 8.85053646e-01]\n",
      "[1.37711671e-89 9.80071453e-27 2.41901526e-08 5.54271000e-08\n",
      " 2.92237566e-05 9.50326444e-02]\n",
      "[2.04277717e-24 1.91072289e-29 1.60579544e-14 1.29835633e-04\n",
      " 3.23200585e-07 5.67583853e-05 4.01124092e-02]\n",
      "[3.82920814e-22 2.72445778e-33 1.88298385e-12 4.85780282e-06\n",
      " 4.80013749e-08 4.11475977e-05 7.84196100e-03]\n",
      "[1.56763703e-22 1.09525853e-29 9.83231124e-14 5.36711970e-05\n",
      " 7.67616877e-08 5.98402991e-06 1.25450197e-02]\n",
      "[9.52172384e-24 1.65022692e-32 1.29211986e-14 1.91849960e-05\n",
      " 1.16901082e-05 7.37640968e-05 2.50220515e-03]\n",
      "[8.01944579e-24 2.16576317e-26 5.19437036e-18 3.80604296e-04\n",
      " 1.07792139e-11 1.56088221e-09 1.80515324e-06]\n",
      "[1.60624021e-24 1.19657612e-25 2.29127477e-15 7.64524455e-06\n",
      " 1.27683633e-06 1.94465538e-05 8.16348586e-02]\n",
      "[2.65540783e-23 1.16992466e-31 3.70413091e-14 1.60267536e-05\n",
      " 6.06699390e-06 4.00302833e-05 7.02408834e-01]\n",
      "[2.75105305e-24 1.10437226e-29 3.17048979e-12 2.03441319e-04\n",
      " 2.01113161e-07 2.73710836e-05 5.67891417e-02]\n",
      "[3.25037378e-24 2.19666993e-24 7.03455131e-17 1.79651332e-03\n",
      " 5.74387242e-12 3.61424098e-09 3.79912417e-06 9.29794667e-02]\n",
      "[4.73148245e-22 4.10507979e-27 1.45070986e-14 1.94824746e-04\n",
      " 4.31016724e-13 1.38098022e-09 1.56860324e-06 6.62932147e-03]\n",
      "[3.17122174e-23 5.68131611e-26 2.09093539e-16 4.60198041e-04\n",
      " 2.18059589e-11 2.00930328e-09 3.98162820e-05 5.52114937e-01]\n",
      "[1.15495151e-23 3.88007080e-26 4.82063089e-17 7.71945890e-04\n",
      " 2.92698443e-11 1.18725247e-09 4.18684096e-07 5.37575960e-04]\n",
      "[1.87370231e-23 2.38867627e-23 9.50731360e-18 3.48711334e-04\n",
      " 1.37955539e-10 1.96105989e-09 8.07905677e-06 6.55715099e-01]\n",
      "[5.80896435e-22 2.29180852e-27 1.05174368e-18 5.25928997e-05\n",
      " 5.03005808e-12 8.32755722e-11 9.41109054e-08 1.52196958e-02]\n",
      "[1.24665987e-23 3.73253348e-26 1.60659666e-15 4.77104599e-04\n",
      " 1.12038696e-11 2.88002914e-09 1.21017128e-05 8.81064521e-01]\n",
      "[5.25704687e-24 2.86949001e-24 4.68455364e-16 2.95116144e-03\n",
      " 1.66646141e-11 2.61292799e-09 9.00948960e-07 7.06149823e-04\n",
      " 1.26671461e-01]\n",
      "[7.62614298e-22 6.78711364e-27 1.28725370e-13 4.01391587e-04\n",
      " 7.15017974e-13 1.03008306e-09 3.42990495e-07 3.83542507e-04\n",
      " 4.65161594e-03]\n",
      "[5.78089786e-23 1.22228404e-25 2.70824527e-15 9.81825502e-04\n",
      " 3.74862323e-11 1.62100104e-09 1.72738834e-05 4.63751286e-04\n",
      " 4.19264385e-01]\n",
      "[1.94395784e-23 7.26627288e-23 1.00419807e-16 6.64949406e-04\n",
      " 2.02440370e-10 1.57782636e-09 2.62922042e-06 4.89969331e-04\n",
      " 5.29515632e-01]\n",
      "[8.53153171e-22 3.92420709e-27 6.91344456e-18 1.09877989e-04\n",
      " 1.37121608e-11 5.81192221e-11 1.95914553e-08 4.90343132e-04\n",
      " 1.37143720e-02]\n",
      "[2.04384878e-23 5.40339224e-26 5.35416427e-15 8.06329507e-04\n",
      " 2.91652702e-11 1.76510764e-09 2.49502497e-06 5.18684033e-04\n",
      " 7.36642904e-01]\n",
      "[3.16370685e-22 8.71135706e-25 3.19001945e-12 2.15347409e-03\n",
      " 1.58731215e-13 2.75906906e-09 8.93150815e-07 5.27447888e-04\n",
      " 1.84186664e-03 4.45674522e-02]\n",
      "[3.52216775e-21 2.19670899e-26 3.25942350e-12 5.18512081e-04\n",
      " 8.25897247e-13 1.41460077e-09 1.52217734e-05 3.28566878e-04\n",
      " 4.61538380e-03 4.09119842e-01]\n",
      "[2.76056154e-21 6.93483868e-24 1.57049829e-13 3.93919756e-04\n",
      " 4.30109541e-12 1.22502863e-09 1.37069195e-06 3.77089263e-04\n",
      " 5.63721314e-03 8.01382123e-01]\n",
      "[1.37233281e-20 1.38275713e-27 7.26395688e-14 9.09530038e-05\n",
      " 1.45857096e-12 1.40273149e-10 4.54332360e-08 3.72296716e-04\n",
      " 1.49726626e-02 4.58258071e-02]\n",
      "[7.70320210e-22 1.71740236e-26 1.32182710e-10 7.53700515e-04\n",
      " 7.32422438e-13 4.04902569e-09 1.10414489e-05 4.24211456e-04\n",
      " 4.55324846e-03 6.82148143e-01]\n",
      "[1.48135372e-21 2.56270078e-24 5.67816083e-11 2.66715733e-03\n",
      " 1.90865891e-13 3.74036517e-09 3.14613369e-05 4.53346622e-04\n",
      " 1.83024726e-03 4.49471213e-02 4.11724748e-01]\n",
      "[1.05960293e-21 6.84136121e-22 4.01402360e-12 2.06270630e-03\n",
      " 9.43839777e-13 3.36825204e-09 3.67925959e-06 5.12006269e-04\n",
      " 2.32427046e-03 4.36749559e-02 7.45386888e-01]\n",
      "[1.11875188e-20 2.10942966e-25 2.29714651e-14 3.62553886e-04\n",
      " 1.08013769e-13 2.97230572e-11 8.92265815e-09 6.13622906e-04\n",
      " 6.53190931e-03 1.64963837e-03 1.69218227e-03]\n",
      "[3.73278037e-22 9.54496132e-25 1.51639649e-10 2.18025186e-03\n",
      " 2.08116921e-13 4.33025221e-09 6.26063834e-06 5.22009817e-04\n",
      " 2.84634561e-03 4.78533647e-02 8.13396438e-01]\n",
      "[9.31775987e-20 7.69232786e-25 2.71810215e-13 4.56983461e-04\n",
      " 6.57147720e-14 3.16877396e-11 5.79355976e-07 4.84073748e-04\n",
      " 6.79360597e-03 1.36815386e-03 1.10694922e-03 2.24516213e-01]\n",
      "[5.99011618e-20 9.84938505e-23 3.10123722e-14 3.71611270e-04\n",
      " 1.14785302e-12 3.71508350e-11 4.07959113e-08 6.23530118e-04\n",
      " 7.12341454e-03 1.66847375e-03 1.80727347e-03 9.48527044e-01]\n",
      "[2.88977882e-19 2.14058616e-25 9.23506286e-13 5.56574290e-04\n",
      " 6.83704282e-15 2.72726507e-12 1.20941304e-06 1.55146926e-03\n",
      " 7.54275944e-04 1.01043818e-03 2.99679931e-06 5.21423722e-04]\n",
      "[3.36594489e-19 2.56968849e-25 1.09917759e-12 5.44468915e-04\n",
      " 5.02795508e-14 2.71546380e-12 1.96711001e-06 1.86263444e-03\n",
      " 7.19380602e-04 1.07474687e-03 4.75053897e-06 1.09912019e-03\n",
      " 7.37988709e-01]\n",
      "[1.73235002e-18 6.83550861e-23 1.10379839e-12 5.85553741e-04\n",
      " 1.08097914e-13 3.29887865e-12 2.86650001e-06 1.60541061e-03\n",
      " 8.16000979e-04 1.02187247e-03 3.22396618e-06 5.28681316e-04\n",
      " 9.57897957e-01]\n",
      "[3.36594489e-19 2.56968849e-25 1.09917759e-12 5.44468915e-04\n",
      " 5.02795508e-14 2.71546380e-12 1.96711001e-06 1.86263444e-03\n",
      " 7.19380602e-04 1.07474687e-03 4.75053897e-06 1.09912019e-03\n",
      " 7.37988709e-01]\n"
     ]
    }
   ],
   "source": [
    "## Automatic Forward Selection\n",
    "import statsmodels.formula.api as sm\n",
    "def forwardSelection(x, sl):\n",
    "    row, column = x.shape\n",
    "    minIndex = -2\n",
    "    k = column\n",
    "\n",
    "    #loop through k-1 size combinations starting at 0 (i)\n",
    "    for i in range(0, k+1):\n",
    "        #print(\"i: \" + str(i) + \" | X\" + str(minIndex) + \" added to model\" +  \" | \" + str(x[0]))\n",
    "        if i > 1 and minIndex != -1:\n",
    "            selected = np.column_stack((selected[:,], x[:,minIndex]))\n",
    "            x = np.delete(x, minIndex, 1)\n",
    "        elif i == 1 and minIndex != -1:\n",
    "            selected = x[:,minIndex]\n",
    "            x = np.delete(x, minIndex, 1)\n",
    "        \n",
    "        minPval = 1\n",
    "        minIndex = -1\n",
    "        #loop through columns k-i times (j) starting at 0\n",
    "        for j in range(0, k-i):\n",
    "            if i > 0:\n",
    "                obj_OLS = sm.OLS(y, np.column_stack((selected[:,], x[:,j]))).fit()\n",
    "            else:\n",
    "                obj_OLS = sm.OLS(y, x[:,j]).fit()\n",
    " \n",
    "            pVal = obj_OLS.pvalues[-1].astype(float)\n",
    "            print(obj_OLS.pvalues)\n",
    "            #print(\"----X\" + str(j) + \": p-value = \" + str(pVal) + \" | Min P-Value = \" + str(minPval) + \"-----\")\n",
    "            if pVal < sl:\n",
    "                if pVal < minPval:\n",
    "                    minPval = pVal\n",
    "                    minIndex = j\n",
    "    return selected\n",
    "    \n",
    "SL = 0.05\n",
    "X_sig = X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]]\n",
    "X_ModeledForward = forwardSelection(X_sig, SL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the features selected by the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.5750e+00, 4.9800e+00, 1.5300e+01, ..., 6.3200e-03, 1.0000e+00,\n",
       "        2.9600e+02],\n",
       "       [6.4210e+00, 9.1400e+00, 1.7800e+01, ..., 2.7310e-02, 2.0000e+00,\n",
       "        2.4200e+02],\n",
       "       [7.1850e+00, 4.0300e+00, 1.7800e+01, ..., 2.7290e-02, 2.0000e+00,\n",
       "        2.4200e+02],\n",
       "       ...,\n",
       "       [6.9760e+00, 5.6400e+00, 2.1000e+01, ..., 6.0760e-02, 1.0000e+00,\n",
       "        2.7300e+02],\n",
       "       [6.7940e+00, 6.4800e+00, 2.1000e+01, ..., 1.0959e-01, 1.0000e+00,\n",
       "        2.7300e+02],\n",
       "       [6.0300e+00, 7.8800e+00, 2.1000e+01, ..., 4.7410e-02, 1.0000e+00,\n",
       "        2.7300e+02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_ModeledForward.shape)\n",
    "X_ModeledForward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Using scikit-learn  build a Linear Regression Model using only the features selected by the forward selection function implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the data into Training Set and Test Set\n",
    "X_sig_train, X_sig_test, y_sig_train, y_sig_test = train_test_split(X_ModeledForward, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Fitting Multiple Linear Regression to Training Set\n",
    "# import LinearRegression class from scikit-learn\n",
    "# initialize a LinearRegression object and fit X and y train sets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "mlrObj_m3 = LinearRegression()\n",
    "mlrObj_m3.fit(X_sig_train, y_sig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model 3 make a prediction on the test set and Calculate Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: \n",
      " [22.6 50.  23.   8.3 21.2 19.9 20.6 18.7 16.1 18.6  8.8 17.2 14.9 10.5\n",
      " 50.  29.  23.  33.3 29.4 21.  23.8 19.1 20.4 29.1 19.3 23.1 19.6 19.4\n",
      " 38.7 18.7 14.6 20.  20.5 20.1 23.6 16.8  5.6 50.  14.5 13.3 23.9 20.\n",
      " 19.8 13.8 16.5 21.6 20.3 17.  11.8 27.5 15.6 23.1 24.3 42.8 15.6 21.7\n",
      " 17.1 17.2 15.  21.7 18.6 21.  33.1 31.5 20.1 29.8 15.2 15.  27.5 22.6\n",
      " 20.  21.4 23.5 31.2 23.7  7.4 48.3 24.4 22.6 18.3 23.3 17.1 27.9 44.8\n",
      " 50.  23.  21.4 10.2 23.3 23.2 18.9 13.4 21.9 24.8 11.9 24.3 13.8 24.7\n",
      " 14.1 18.7 28.1 19.8 26.7 21.7 22.  22.9 10.4 21.9 20.6 26.4 41.3 17.2\n",
      " 27.1 20.4 16.5 24.4  8.4 23.   9.7 50.  30.5 12.3 19.4 21.2 20.3 18.8\n",
      " 33.4 18.5 19.6 33.2 13.1  7.5 13.6 17.4  8.4 35.4 24.  13.4 26.2  7.2\n",
      " 13.1 24.5 37.2 25.  24.1 16.6 32.9 36.2 11.   7.2 22.8 28.7] \n",
      "\n",
      "Predict Set: \n",
      " [24.67908024 23.92880684 29.48092818 12.03270293 21.30919509 19.17352252\n",
      " 20.37758536 21.23489071 18.76934955 20.56617036  5.5810561  17.02526238\n",
      " 17.15581931  5.42147833 40.3085712  32.17527919 22.40858331 36.587779\n",
      " 30.79780722 23.0248887  24.69861046 24.64198083 20.77620033 30.26531743\n",
      " 22.15310435 10.53856112 17.65838677 18.19979733 35.78435377 21.00519462\n",
      " 18.35954853 17.6874823  19.75847977 23.83907154 29.19216154 19.40985426\n",
      " 11.09266359 24.88815204 18.08607986 15.6477159  25.83440584 20.57847302\n",
      " 22.08384281 15.64223872 22.77645981 25.10718513 19.73144892 22.92013299\n",
      "  9.6379183  24.46540513 21.2542394  17.14123037 24.46505209 29.6293637\n",
      " 13.63083122 21.32912642 20.40907523 15.17213194 14.63426703 22.30513812\n",
      " 17.15966762 21.43856174 32.7064441  31.02414929 17.59254968 32.66348908\n",
      " 18.76638933 19.49837577 19.48793149 22.66953958 22.98916932 23.93340782\n",
      " 30.46432658 28.62666259 25.95376805  5.02988835 36.89749769 23.64313456\n",
      " 27.32609942 19.23330331 28.42833798 19.30466284 19.13120044 38.07629459\n",
      " 39.52430181 23.49331018 24.97373743 16.35932165 25.98667021 16.62977555\n",
      " 15.64698331 13.45907027 24.28805779 30.9974349  22.25856614 19.88191683\n",
      "  0.37298983 25.07603076 16.01171303 17.6645595  25.17195735 22.59513027\n",
      " 32.84969352 21.69480165 27.3623866  23.30631188  6.8169344  14.96672703\n",
      " 22.31905143 28.91579972 33.3633926  13.27298412 19.98945825 20.75640987\n",
      " 12.29100872 23.39699168  5.33362338 19.94294328  9.27819002 44.69285639\n",
      " 30.54474904 12.45000059 17.40982903 21.3856495  23.61351452 20.41928928\n",
      " 35.21721371 13.49328185 20.77735792 35.30433668 19.48113362 13.7068851\n",
      " 14.16867556 23.13233729 14.82911779 30.94945093 25.23944546 15.23214316\n",
      " 23.86678497  9.90173961 14.95467507 20.73422515 32.84825581 27.62344024\n",
      " 25.40953239 15.53103095 30.90216858 27.8762464  14.35683584  7.50171315\n",
      " 28.50718526 25.20674081]\n",
      "\n",
      " Mean Squared Error:  27.04657009592729\n"
     ]
    }
   ],
   "source": [
    "# Predicting on Test Set\n",
    "y_pred_m3 = mlrObj_m3.predict(X_sig_test)\n",
    "print( \"Test Set: \\n\", y_sig_test,\"\\n\")\n",
    "print( \"Predict Set: \\n\", y_pred_m3)\n",
    "\n",
    "#Mean Squared Error\n",
    "mse_m3 = np.square(np.subtract(y_pred_m3, y_sig_test)).mean()\n",
    "print(\"\\n Mean Squared Error: \",mse_m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function backwardElimination(x, sl) to implement the backward feature elimination technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Automatic Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "def backwardElimination(x, sl):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        obj_OLS = sm.OLS(y,x).fit()\n",
    "        maxVar = max(obj_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if(obj_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    obj_OLS.summary()\n",
    "    return x\n",
    "SL = 0.05\n",
    "X_sig_bm = X[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "X_Modeled_bm = backwardElimination(X_sig_bm, SL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the features selected by the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 6.3200e-03, 1.8000e+01, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [1.0000e+00, 2.7310e-02, 0.0000e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [1.0000e+00, 2.7290e-02, 0.0000e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [1.0000e+00, 6.0760e-02, 0.0000e+00, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0000e+00, 1.0959e-01, 0.0000e+00, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [1.0000e+00, 4.7410e-02, 0.0000e+00, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_Modeled_bm.shape)\n",
    "X_Modeled_bm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Using scikit-learn  build a Linear Regression Model using only the features selected by the backward elimination function implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the data into Training Set and Test Set\n",
    "X_sig_train_bm, X_sig_test_bm, y_sig_train_bm, y_sig_test_bm = train_test_split(X_Modeled_bm, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Fitting Multiple Linear Regression to Training Set\n",
    "# import LinearRegression class from scikit-learn\n",
    "# initialize a LinearRegression object and fit X and y train sets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "mlrObj_m4 = LinearRegression()\n",
    "mlrObj_m4.fit(X_sig_train_bm, y_sig_train_bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model 4 make a prediction on the test set and Calculate Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: \n",
      " [22.6 50.  23.   8.3 21.2 19.9 20.6 18.7 16.1 18.6  8.8 17.2 14.9 10.5\n",
      " 50.  29.  23.  33.3 29.4 21.  23.8 19.1 20.4 29.1 19.3 23.1 19.6 19.4\n",
      " 38.7 18.7 14.6 20.  20.5 20.1 23.6 16.8  5.6 50.  14.5 13.3 23.9 20.\n",
      " 19.8 13.8 16.5 21.6 20.3 17.  11.8 27.5 15.6 23.1 24.3 42.8 15.6 21.7\n",
      " 17.1 17.2 15.  21.7 18.6 21.  33.1 31.5 20.1 29.8 15.2 15.  27.5 22.6\n",
      " 20.  21.4 23.5 31.2 23.7  7.4 48.3 24.4 22.6 18.3 23.3 17.1 27.9 44.8\n",
      " 50.  23.  21.4 10.2 23.3 23.2 18.9 13.4 21.9 24.8 11.9 24.3 13.8 24.7\n",
      " 14.1 18.7 28.1 19.8 26.7 21.7 22.  22.9 10.4 21.9 20.6 26.4 41.3 17.2\n",
      " 27.1 20.4 16.5 24.4  8.4 23.   9.7 50.  30.5 12.3 19.4 21.2 20.3 18.8\n",
      " 33.4 18.5 19.6 33.2 13.1  7.5 13.6 17.4  8.4 35.4 24.  13.4 26.2  7.2\n",
      " 13.1 24.5 37.2 25.  24.1 16.6 32.9 36.2 11.   7.2 22.8 28.7] \n",
      "\n",
      "Predict Set: \n",
      " [24.67908024 23.92880684 29.48092818 12.03270293 21.30919509 19.17352252\n",
      " 20.37758536 21.23489071 18.76934955 20.56617036  5.5810561  17.02526238\n",
      " 17.15581931  5.42147833 40.3085712  32.17527919 22.40858331 36.587779\n",
      " 30.79780722 23.0248887  24.69861046 24.64198083 20.77620033 30.26531743\n",
      " 22.15310435 10.53856112 17.65838677 18.19979733 35.78435377 21.00519462\n",
      " 18.35954853 17.6874823  19.75847977 23.83907154 29.19216154 19.40985426\n",
      " 11.09266359 24.88815204 18.08607986 15.6477159  25.83440584 20.57847302\n",
      " 22.08384281 15.64223872 22.77645981 25.10718513 19.73144892 22.92013299\n",
      "  9.6379183  24.46540513 21.2542394  17.14123037 24.46505209 29.6293637\n",
      " 13.63083122 21.32912642 20.40907523 15.17213194 14.63426703 22.30513812\n",
      " 17.15966762 21.43856174 32.7064441  31.02414929 17.59254968 32.66348908\n",
      " 18.76638933 19.49837577 19.48793149 22.66953958 22.98916932 23.93340782\n",
      " 30.46432658 28.62666259 25.95376805  5.02988835 36.89749769 23.64313456\n",
      " 27.32609942 19.23330331 28.42833798 19.30466284 19.13120044 38.07629459\n",
      " 39.52430181 23.49331018 24.97373743 16.35932165 25.98667021 16.62977555\n",
      " 15.64698331 13.45907027 24.28805779 30.9974349  22.25856614 19.88191683\n",
      "  0.37298983 25.07603076 16.01171303 17.6645595  25.17195735 22.59513027\n",
      " 32.84969352 21.69480165 27.3623866  23.30631188  6.8169344  14.96672703\n",
      " 22.31905143 28.91579972 33.3633926  13.27298412 19.98945825 20.75640987\n",
      " 12.29100872 23.39699168  5.33362338 19.94294328  9.27819002 44.69285639\n",
      " 30.54474904 12.45000059 17.40982903 21.3856495  23.61351452 20.41928928\n",
      " 35.21721371 13.49328185 20.77735792 35.30433668 19.48113362 13.7068851\n",
      " 14.16867556 23.13233729 14.82911779 30.94945093 25.23944546 15.23214316\n",
      " 23.86678497  9.90173961 14.95467507 20.73422515 32.84825581 27.62344024\n",
      " 25.40953239 15.53103095 30.90216858 27.8762464  14.35683584  7.50171315\n",
      " 28.50718526 25.20674081]\n",
      "\n",
      " Mean Squared Error:  27.046570095927382\n"
     ]
    }
   ],
   "source": [
    "# Predicting on Test Set\n",
    "y_pred_m4 = mlrObj_m4.predict(X_sig_test_bm)\n",
    "print( \"Test Set: \\n\", y_sig_test_bm,\"\\n\")\n",
    "print( \"Predict Set: \\n\", y_pred_m4)\n",
    "\n",
    "#Mean Squared Error\n",
    "mse_m4 = np.square(np.subtract(y_pred_m4, y_sig_test_bm)).mean()\n",
    "print(\"\\n Mean Squared Error: \",mse_m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
